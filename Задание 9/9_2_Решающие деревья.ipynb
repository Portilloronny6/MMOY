{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## О задании\n",
    "\n",
    "Задание состоит из двух разделов:\n",
    "1. В первом разделе - применение деревьев из **sklearn** для задачи классификации, построение разделяющих поверхностей для различных датасетов, анализ их зависимости от гиперпараметров.\n",
    "2. Во втором разделе - реализация собственных решающих деревьев, сравнение со стандартной имплиментацией из **sklearn**; тестирование деревьев и сравнение различных подходов к кодированию категориальных признаков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import Colormap, ListedColormap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Решающие деревья. Визуализация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Рассмотрим два простых двумерных датасета, сформированных с помощью `make_moons`, `make_circles` и изучим, как ведет себя разделяющая поверхность в зависимости от различных гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "datasets = [\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=42),\n",
    "    make_moons(noise=0.2, random_state=42),\n",
    "    make_classification(n_classes=3, n_clusters_per_class=1, n_features=2, class_sep=.8, random_state=3,\n",
    "                        n_redundant=0., )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "palette = sns.color_palette(n_colors=3)\n",
    "cmap = ListedColormap(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "for i, (x, y) in enumerate(datasets):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap, alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 1\n",
    "\n",
    "Для каждого датасета обучите решающее дерево с параметрами по умолчанию, предварительно разбив выборку на обучающую и тестовую. Постройте разделящие поверхности (для этого воспользуйтесь функцией `plot_surface`, пример ниже). Вычислите значение **accuracy** на обучающей и тестовой выборках. Оцените степень переобученности деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train a decision tree with default parameters, after dividing the sample into training and test sets\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X, y = dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    tree = DecisionTreeClassifier(random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    print('Точность на обучающем наборе: {:.3f}'.format(tree.score(X_train, y_train)))\n",
    "    print('Точность на тестовом наборе: {:.3f}'.format(tree.score(X_test, y_test)))\n",
    "    print('Переобученность: {:.3f}'.format(1 - tree.score(X_test, y_test) / tree.score(X_train, y_train)))\n",
    "    print()\n",
    "    # Визуализация разделяющей поверхности\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_surface(tree, X, y)\n",
    "    plt.title(dataset.__class__.__name__)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_surface(clf, X, y):\n",
    "    plot_step = 0.01\n",
    "    palette = sns.color_palette(n_colors=len(np.unique(y)))\n",
    "    cmap = ListedColormap(palette)\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.3)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, alpha=.7, edgecolors=np.array(palette)[y], linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Пример:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = datasets[2]\n",
    "lr = LinearRegression().fit(X, y)\n",
    "plot_surface(lr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 2\n",
    "\n",
    "Попробуйте перебрать несколько параметров для регуляризации (напр. `max_depth`, `min_samples_leaf`). Для каждого набора гиперпараметров постройте разделяющую поверхность, выведите обучающую и тестовую ошибки. Можно делать кросс-валидацию или просто разбиение на трейн и тест, главное делать каждый раз одинаковое разбиение, чтобы можно было корректно сравнивать (напоминание: итоговое дерево сильно зависит от небольшого изменения обучающей выборки). Проследите, как меняется разделяющая поверхность и обобщающая способность. Почему так происходит, одинаково ли изменение для разных датасетов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate over several parameters for regularization (eg. max_depth, min_samples_leaf)\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X, y = dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    for max_depth in range(1, 3):\n",
    "        for min_samples_leaf in range(1, 3):\n",
    "            tree = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "            tree.fit(X_train, y_train)\n",
    "            print('Точность на обучающем наборе: {:.3f}'.format(tree.score(X_train, y_train)))\n",
    "            print('Точность на тестовом наборе: {:.3f}'.format(tree.score(X_test, y_test)))\n",
    "            print('Переобученность: {:.3f}'.format(1 - tree.score(X_test, y_test) / tree.score(X_train, y_train)))\n",
    "            print()\n",
    "            # Визуализация разделяющей поверхности\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plot_surface(tree, X, y)\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Решающие деревья своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В этой части нужно реализовать свой класс для обучения решающего дерева в задаче бинарной классификации с возможностью обработки вещественных и категориальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 3\n",
    "\n",
    "Реализуйте функцию find_best_split для получения оптимального разбиения по заданному признаку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a find_best_split function to get the best split of X and y for a given feature\n",
    "def find_best_split(X, y, feature):\n",
    "    \"\"\"\n",
    "    Find the best split of X and y for a given feature.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target vector.\n",
    "    feature : int\n",
    "        Feature index.\n",
    "    Returns\n",
    "    -------\n",
    "    best_threshold : float\n",
    "        Best threshold value.\n",
    "    best_score : float\n",
    "        Best score value.\n",
    "    \"\"\"\n",
    "    # Выберите оптимальный порог и оценку для данного признака\n",
    "    best_threshold = None\n",
    "    best_score = 0\n",
    "    X_train, X_test, y_train, y_test = 0, 0, 0, 0\n",
    "    for threshold in np.unique(X[:, feature]):\n",
    "        X_train, X_test, y_train, y_test, score = score_split(X, y, feature, threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    return X_train, X_test, y_train, y_test, best_threshold, best_score\n",
    "\n",
    "\n",
    "# Create score_split function to calculate the score of a split\n",
    "def score_split(X, y, feature, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the score of a split.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target vector.\n",
    "    feature : int\n",
    "        Feature index.\n",
    "    threshold : float\n",
    "        Threshold value.\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        Score value.\n",
    "    \"\"\"\n",
    "    X_left = X[X[:, feature] <= threshold]\n",
    "    X_right = X[X[:, feature] > threshold]\n",
    "    y_left = y[X[:, feature] <= threshold]\n",
    "    y_right = y[X[:, feature] > threshold]\n",
    "    n_left = X_left.shape[0]\n",
    "    n_right = X_right.shape[0]\n",
    "    n_total = n_left + n_right\n",
    "    p_left = np.sum(y_left) / n_left\n",
    "    p_right = np.sum(y_right) / n_right\n",
    "    p_total = np.sum(y) / n_total\n",
    "    score = np.abs(p_total - (p_left * n_left + p_right * n_right) / n_total) / n_total\n",
    "    return X_right, X_left, y_right, y_left, score\n",
    "\n",
    "\n",
    "find_best_split(X, y, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 4\n",
    "Загрузите таблицу [students.csv](https://drive.google.com/file/d/0B2zoFVYw1rN3a0d0Zm43TzQ4aUU/view?usp=sharing) (это немного преобразованный датасет [User Knowledge](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)). В ней признаки объекта записаны в первых пяти столбцах, а в последнем записана целевая переменная (класс: 0 или 1). Постройте на одном изображении пять кривых \"порог — значение критерия Джини\" для всех пяти признаков. Отдельно визуализируйте scatter-графики \"значение признака — класс\" для всех пяти признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 5\n",
    "\n",
    "Исходя из кривых значений критерия Джини, сделайте вывод: по какому признаку нужно производить деление выборки на два поддерева? Согласуется ли этот результат с визуальной оценкой scatter-графиков? Как можно охарактеризовать вид кривой для \"хороших\" признаков, по которым выборка делится почти идеально? Чем отличаются кривые для признаков, по которым деление практически невозможно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 6 (дополнительно)\n",
    "\n",
    "Выполните собственную реализацию класса DecisionTree для работы с решающими деревьями.\n",
    "\n",
    "Выбор лучшего разбиения необходимо производить по критерию Джини. \n",
    "\n",
    "Критерий останова: все объекты в листе относятся к одному классу или ни по одному признаку нельзя разбить выборку. \n",
    "\n",
    "Ответ в листе: наиболее часто встречающийся класс в листе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 7 (для тех, кто выполнил задание 6)\n",
    "\n",
    "Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). Вам нужно скачать таблицу agaricus-lepiota.data (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)), прочитать ее с помощью pandas, применить к каждому столбцу LabelEncoder (из sklearn), чтобы преобразовать строковые имена категорий в натуральные числа. Первый столбец — это целевая переменная (e — edible, p — poisonous). Оценка качества будет выполняться с помощью **accuracy**, поэтому не очень важно, что будет классом 1, а что — классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите значение **accuracy**.\n",
    "\n",
    "Должно получиться значение **accuracy**, равное единице (или очень близкое к единице), и не очень глубокое дерево."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 8 (для тех, кто выполнил задания 6 и 7)\n",
    "Реализуйте в классе DecisionTree поддержку параметров max_depth, min_samples_split и min_samples_leaf по аналогии с DecisionTreeClassifier. Постройте графики зависимости качества предсказания в зависимости от этих параметров для набора данных [tic-tac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Решение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}